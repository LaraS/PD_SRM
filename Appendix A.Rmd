---
title: "Appendix A: Simulation Studies for Model Selection"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
# Simulate data: The "true model"

Data are simulated using different true models. In particular, the models contain different options for the factor loadings (FL) of the family component (FC).
\begin{itemize}
\item Option 1: all observed scores are of equal importance for the family component. Therefore, every loading of the FC is fixed to 1. So, their sum will be equal to 6. This specification strategy is identical to the one of the traditional SRM.
\item[] o1 <- "FC =~ 1*MF + 1*MO + 1*MY + 1*FO + 1*FY + 1*YO"
\item Option 2: some FL's are more important than others, but sum of all is equal to 6 (lambda approach).
\item[] o2 <- "FC =~ 1.4*MF + 0.8*MO + 0.8*MY + 0.8*FO + 0.8*FY + 1.4*YO"
\item Option 3: fix 1 FL to 1 and for the other FL's we will use the lambda approach (combination of ULI and lambda approach) => sum is equal to 6.
\item[] o3 <- "FC =~ 1*MF + 0.9*MO + 1.2*MY + 1.1*FO + 1.2*FY + 0.6*YO"
\item Option 4: lambda approach for each person separately => In total, sum is equal to 6.
\item[] o4 <- "FC =~ 0.7*MF + 1.1*MO + 1.2*MY + 1.2*FO + 1.1*FY + 0.7*YO"
\end{itemize}


```{r, eval = F, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51)}
# Factor loadings of FC:
# option 1: all observed scores are of equal importance for the family component (FC) 
# => constrain every loading to 1, sum will be equal to 6 (identical to simulation
#                                                          study with traditional SRM)
  o1 <- "FC =~ 1*MF + 1*MO + 1*MY + 1*FO + 1*FY + 1*YO"
# option 2: some FL's are more important than others, but sum of all is equal to 
# six (lambda approach)
  o2 <- "FC =~ 1.4*MF + 0.8*MO + 0.8*MY + 0.8*FO + 0.8*FY + 1.4*YO"
# option 3: fix 1 FL to 1 and for the other FL's we will use the lambda approach
# (based on model 3a; lambda approach) => sum is equal to 6
  o3 <- "FC =~ 1*MF + 0.9*MO + 1.2*MY + 1.1*FO + 1.2*FY + 0.6*YO"
# option 4: lambda for each person (based on model 3b) => sum is equal to 6
  o4 <- "FC =~ 0.7*MF + 1.1*MO + 1.2*MY + 1.2*FO + 1.1*FY + 0.7*YO"
FC <- c(o1,o2,o3,o4)

for (i in 1:4){ # Factor loadings of FC
  true_t <- paste0(FC[i], 
     '
     I.M =~ 1*MF + 1*MO + 1*MY
     I.F =~ 1*MF + 1*FO + 1*FY 
     I.O =~ 1*MO  + 1*FO + 1*YO
     I.Y =~ 1*MY  + 1*FY + 1*YO
     D.MF =~ 1*MF
     D.MO =~ 1*MO
     D.MY =~ 1*MY
     D.FO =~ 1*FO
     D.FY =~ 1*FY
     D.OY =~ 1*YO
     
     # Variances
     FC ~~ 2*FC
     I.M ~~ 1*I.M
     I.F ~~ 1*I.F
     I.O ~~ 1*I.O
     I.Y ~~ 1*I.Y
     D.MF ~~ 0.5*D.MF
     D.MO ~~ 0.5*D.MO
     D.MY ~~ 0.5*D.MY
     D.FO ~~ 0.5*D.FO
     D.FY ~~ 0.5*D.FY
     D.OY ~~ 0.5*D.OY
     
     # Intercepts
     FC ~ 4*1
     I.M ~ -0.8*1
     I.F ~ -0.8*1
     I.O ~ 0.8*1
     I.Y ~ 0.8*1
     D.MF ~ 1*1
     D.MO ~ -0.5*1
     D.MY ~ -0.5*1
     D.FO ~ -0.5*1
     D.FY ~ -0.5*1
     D.OY ~ 1*1
     ')
  assign(paste0("PDSRM_th_FC", i), true_t)
  }
truemodel <- list(option1 = PDSRM_th_FC1, option2 = PDSRM_th_FC2, option3 = PDSRM_th_FC3, 
                  option4 = PDSRM_th_FC4)
```

\newpage
# Fit different types of models with the simulated data
In this section, different kinds of models are fitted with the simulated data from above.

In the following output, different kinds of tables are shown. The first four tables (option1_fit - option4_fit) contain information about 5 different fit measures: The CFI (with a cut-off of .90 and .95), the TLI (with a cut-off of .90 and .95), the RMSEA (with a cut-off of .08 and .04), the SRMR (with a cut-off of .10 and .08) and the p-value of the chi-square (p>.05: there is no significant difference between the data and the model). All results are given in percentage.

The fifth table provides information about how many models converged (\%). The last table shows how many models contained at least one negative variance (\%). 

*Note:* For each model, the model syntax is printed. The data simulating loop is only printed for model 1 as this remains almost identical (only the name of the model changes).

# Method 1: PD SRM as an adaptation of Kenny's SRM (model 1)
In this model, the factor loadings are all fixed to 1. This is similar to the traditional SRM.

*Note:* We expect that the chi-square test yields more significant results with larger samples, as documented in literature.
```{r, eval = F, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51)}
  SRM_pd <- '
  # Latent variables
  FC =~ 1*MF + 1*MO + 1*MY + 1*FO + 1*FY + 1*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Intragen. covariances
  #   I.M ~~ I.F
  #   I.O ~~ I.Y
  
  # Variances
  FC ~~ VAR.FC*FC
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAR.D.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FC ~ mean.FC*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '

# Simulations
#############
  setwd("/user/home/gent/vsc408/vsc40825/modelselectie/model1/resultaten")
  N <- 500 # number of simulations
  nobs <- c(50,75,100,125,150,200,500,1000) # different sample sizes
  a <- 1 
  for( k in 1:4){ # which option for FC
    for (j in 1:length(nobs)){
      cfi <- c()
      tli <- c()
      rmsea <- c()
      chi2 <- c()
      srmr <- c()
      neg <- c()
      for(i in 1:N) {
        tryCatch({
          sim.data <- simulateData(truemodel[[k]], seed = a, sample.nobs=nobs[j])
          fit <- lavaan(SRM_pd, data=sim.data)
          cfi[i] <- fitMeasures(fit, "cfi")
          rmsea[i] <- fitMeasures(fit, "rmsea")
          chi2[i] <- fitMeasures(fit, "pvalue")
          tli[i] <- fitMeasures(fit, "tli")
          srmr[i] <- fitMeasures(fit, "srmr")
          name <- paste('nobs', nobs[j], sep='')
          fitvalues <- list(TLI = tli, CFI = cfi, RMSEA = rmsea, CHI2 = chi2, SRMR = srmr)
          neg[i] <- length(which(parameterEstimates(fit)[c(25:35),"est"] <0))
          a <- a + 1
        }, error=function(e){cat("ERROR i=",i, "j=",j,"k=",k , ":",conditionMessage(e),
                                 "\n")})
      } 
      if (!is.null(cfi)){ 
        # only write table when there is at least 1 model that converged 
        write.table(fitvalues, paste0("dataTO",k,"_m1_fit_nobs",nobs[j], ".txt")) 
        # T = theoretical, O = which option for FC
        write.table(neg, paste0("dataTO",k,"_m1_neg_nobs",nobs[j], ".txt"))
      }
    }
  }
```

### Results model 1
Below, the code for analyzing these results is provided. This is only printed once, for the other models the output is directly provided.
```{r setup, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51)}
  setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model1/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", 
                         "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) 
  # is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m1_fit_nobs",nobs[j]),
         read.table(paste0("dataTO",k,"_m1_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretical data
  # o = which option for FC
  # m = which model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                          "$CFI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO", k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$CFI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$TLI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$TLI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .04))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$CHI2")))) > .05))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .10))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m1_neg_nobs",nobs[j]),
           read.table(paste0("dataTO",k,"_m1_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_neg_nobs",nobs[j], 
                                                         "[,1]")))) != 0))/
      length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations that converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                "$CFI")))))/5  
  }
  }
  
  # results in table format
  option1.1_fit <- fit_all[c(1:8),]
    rownames(option1.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  option1.2_fit <- fit_all[c(9:16),]
    rownames(option1.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  option1.3_fit <- fit_all[c(17:24),]
    rownames(option1.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  option1.4_fit <- fit_all[c(25:32),]
    rownames(option1.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                         "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                      "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  option1.1_fit
  option1.2_fit
  option1.3_fit
  option1.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

## Conclusion model 1
If in reality all observed scores are of equal importance for the family component (*option 1* of the simulated data), this model suits very well with these simulated data (as expected).  

If, however, some observed scores are more important than others (*option 2, 3 and 4*), this model will terribly underperform.

*Note:* The RMSEA will underperform with almost all presented models.

\newpage

# Method 2: Set factor loadings free of FC, but fix at least 1
In models 2a, 2b and 2c, the FL's of the family component are constrained: 
\begin{itemize}
\item[(2a)] the FL's of the dyads of the same generation are fixed to 1
\item[(2b)] the FL's of the parent-child dyads are fixed to 1
\item[(2c)] the FL's of the same person are constrained (here: mother)
\end{itemize}
Here, the assumption is made that the fixed observed variables are of equal importance for the family component. They also serve as the baseline to which the other observed scores can be compared. 

Model 2d uses a similar approach to ULI (i.e., unit loading identification) for the family component. Here, the FL of one observed score is constrained to 1, while the others are set free. The constrained observed score serves as a baseline to which the other observed scores can be compared: Are they more (or less) important for the family component?

In search of a general version of the PD SRM, a priori, model 2d is the most suitable of all three models. Models 2a, 2b and 2c can be used for specific research questions. 

## Model 2a: Constrain dyads from the same generation (6df)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
  SRM_pd2a <- '
  # Latent variables
  FC =~ 1*MF + MO + MY + FO + FY + 1*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Variances
  FC ~~ VAR.FC*FC
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAD.R.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FC ~ mean.FC*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '  
```

### Results model 2a
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2a/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04",
                         "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on 
  # a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j]),
         read.table(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$CFI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$CFI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$TLI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$TLI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .04))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$CHI2")))) > .05))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .10))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2a_neg_nobs",nobs[j]),
           read.table(paste0("dataTO",k,"_m2a_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_neg_nobs",nobs[j],
                                                         "[,1]")))) != 0))/
      length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                "$CFI")))))/5  
  }
  }
  
  # results in table format
  option2a.1_fit <- fit_all[c(1:8),]
    rownames(option2a.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  option2a.2_fit <- fit_all[c(9:16),]
    rownames(option2a.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  option2a.3_fit <- fit_all[c(17:24),]
    rownames(option2a.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  option2a.4_fit <- fit_all[c(25:32),]
    rownames(option2a.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                         "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                      "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2a.1_fit,2)
  option2a.2_fit
  option2a.3_fit
  option2a.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

\begin{itemize}
\item Option 1: Only 21\% of all models converged with n = 50. With the other three options, all models converged.
\item[] Starting from n = 75: good performance (exception: RMSEA performs only well with larger samples)
\item Option 2 and 3: Also perform well with n = 50 (*Note:* with option 3 the chi-square test becomes more significant as sample size increases) .
\item Option 4: Performs well (expectation chi-square if n $\leq$ 100)
\item With n = 50: data simulated under option 1 and 2 result in fitted models with the most negative variances.
\end{itemize}
RMSEA only performs adequately starting from n = 200
\newpage

## Model 2b: Constrain the parent-child dyads (8df)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
  SRM_pd2b <- '
  # Latent variables
  FC =~ MF + 1*MO + 1*MY + 1*FO + 1*FY + YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Variances
  FC ~~ VAR.FC*FC
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAD.R.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FC ~ mean.FC*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '  
```

### Results model 2b
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2b/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2b_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2b_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option2b.1_fit <- fit_all[c(1:8),]
    rownames(option2b.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2b.2_fit <- fit_all[c(9:16),]
    rownames(option2b.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2b.3_fit <- fit_all[c(17:24),]
    rownames(option2b.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2b.4_fit <- fit_all[c(25:32),]
    rownames(option2b.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2b.1_fit,2)
  option2b.2_fit
  option2b.3_fit
  option2b.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

Similar results as with the previous model
\begin{itemize}
\item Option 1: Only 15\% of all models converged with n = 50. With the other three options, all models converged.
\item[] if n $\geq$ 75: fit indices all perform very well 
\item Option 2: also good results with n=50
\item Option 3: CFI, TLI and SRMR perform good. 
\end{itemize}
Exception: RMSEA only performs well in larger samples.
\newpage

## Model 2c: Constrain everything of 1 person (here: mother)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd2c <- '
# Latent variables
FC =~ 1*MF + 1*MO + 1*MY + FO + FY + YO
I.M =~ 1*MF + 1*MO + 1*MY
I.F =~ 1*MF + 1*FO + 1*FY 
I.O =~ 1*MO  + 1*FO + 1*YO
I.Y =~ 1*MY  + 1*FY + 1*YO
D.MF =~ 1*MF
D.MO =~ 1*MO
D.MY =~ 1*MY
D.FO =~ 1*FO
D.FY =~ 1*FY
D.OY =~ 1*YO

# Variances
FC ~~ VAR.FC*FC
I.M ~~ VAR.I.M*I.M
I.F ~~ VAR.I.F*I.F
I.O ~~ VAR.I.O*I.O
I.Y ~~ VAR.I.Y*I.Y
D.MF ~~ VAR.D.MF*D.MF
D.MO ~~ VAR.D.MO*D.MO
D.MY ~~ VAD.R.MY*D.MY
D.FO ~~ VAR.D.FO*D.FO
D.FY ~~ VAR.D.FY*D.FY
D.OY ~~ VAR.D.OY*D.OY

# Intercepts
FC ~ mean.FC*1
I.M ~ mean.I.M*1
I.F ~ mean.I.F*1
I.O ~ mean.I.O*1
I.Y ~ mean.I.Y*1
D.MF ~ mean.D.MF*1
D.MO ~ mean.D.MO*1
D.MY ~ mean.D.MY*1
D.FO ~ mean.D.FO*1
D.FY ~ mean.D.FY*1
D.OY ~ mean.D.OY*1

# Constraints
mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
mean.D.MF + mean.D.MO + mean.D.MY == 0
mean.D.MF + mean.D.FO +  mean.D.FY == 0
mean.D.MY + mean.D.FY + mean.D.OY == 0
mean.D.MO + mean.D.FO + mean.D.OY == 0
'    
```

### Results model 2c
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2c/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option2c.1_fit <- fit_all[c(1:8),]
    rownames(option2c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2c.2_fit <- fit_all[c(9:16),]
    rownames(option2c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2c.3_fit <- fit_all[c(17:24),]
    rownames(option2c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2c.4_fit <- fit_all[c(25:32),]
    rownames(option2c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2c.1_fit,2)
  option2c.2_fit
  option2c.3_fit
  option2c.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

\begin{itemize}
\item Option 1: Only 17\% and 38\% of all models converged with sample sizes of 50 and 75, respectively. For the other sample sizes, the results are all good.
\item Option 2: Except for the smallest sample, model 2c underperforms. This is the case with almost all fit indices (exception: CFI90)
\item Option 3: In general, good fit with n $\geq$ 125 (exceptions: RMSEA and Chi-square)
\item Option 4: In general, good fit with n $\geq$ 200 (exceptions: RMSEA and Chi-square)
\item Option 2-4: Chi-square test (and RMSEA) becomes worse with increasing sample sizes. This is what we would expect for the chi-square test. Also, TLI performs badly with option 2.
\item Negative variances seem to be present with all options in smaller samples
\end{itemize}
Conclusion:  of all models, this model seems to be the least suitable.


\newpage
## Model 2d:  Set factor loadings free of FC, but fix 1 (ULI; 5df)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
 SRM_pd2d <- '
  # Latent variables
  FC =~ 1*MF + MO + MY + FO + FY + YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Variances
  FC ~~ VAR.FC*FC
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAD.R.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FC ~ mean.FC*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '  
```

### Results model 2d
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2d/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2d_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2d_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option2d.1_fit <- fit_all[c(1:8),]
    rownames(option2d.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2d.2_fit <- fit_all[c(9:16),]
    rownames(option2d.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2d.3_fit <- fit_all[c(17:24),]
    rownames(option2d.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2d.4_fit <- fit_all[c(25:32),]
    rownames(option2d.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2d.1_fit,2)
  option2d.2_fit
  option2d.3_fit
  option2d.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```
Results:
\begin{itemize}
\item If all observed scores are in reality of equal importance for the family component (i.e. $Option 1$), this model underperforms with samples smaller than 200. Only 1.4\% of all models converged with n = 50 and 72.6\% of all models with n = 150 did. Also, a lot of negative variances seem to be present in small samples. For the models that did converged, results were good for samples if n $\geq$ 75 or 100. 
\item The other three kinds of simulated data ($Option 2, 3$ and $4$) perform very well: all models converged. The fit indices and the chi-square difference tests showed an excellent model fit. $Note:$ Also the RMSEA performs well.
\end{itemize}



\newpage

# Method 3: lambda approach
In this section, the lambda approach for the factor loadings of the family component is used. This is an alternative identification strategy where the mean of the factor loadings equals 1. Model 3c is the most general model with the most straightforward interpretation of the components.

# Model 3a: Constrain one FL as a Reference (Sum other FL's = 5).
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3a <- '
  # Latent variables
  FC =~ 1*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO

  # Variances
  FC ~~ VAR.FC*FC
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAR.D.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY

  # Intercepts
  FC ~ mean.FC*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1

  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  # set constraints on factor loadings FC for identifiability
  lambdaMO+ lambdaMY+ lambdaFO + lambdaFY + lambdaYO==5
  '
```

### Results model 3a
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3a/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3a_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3a_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3a.1_fit <- fit_all[c(1:8),]
    rownames(option3a.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3a.2_fit <- fit_all[c(9:16),]
    rownames(option3a.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3a.3_fit <- fit_all[c(17:24),]
    rownames(option3a.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3a.4_fit <- fit_all[c(25:32),]
    rownames(option3a.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  option3a.1_fit
  option3a.2_fit
  option3a.3_fit
  option3a.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

All models converged. With small samples, a lot of negative variances where found.

Options 1 and 3: CFI and chi-square test perform well with both small (n = 50) and larger samples. TLI performs well starting from n = 75. RMSEA only performs adequately with samples of 200 families or more.

Option 2 and 4: chi-square test and RMSEA perform worse with larger samples. The former is what we could expect.

Option 3: Good results if n $\geq$ 75 for least stringent cut-offs.

Drawback: not easy to interpret the different components.

\newpage

# Model 3b: lambda for every person
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3b <- '
  # Latent variables
  FC =~ lambdaMF*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO

  # Variances
  FC ~~ VAR.FC*FC
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAR.D.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY

  # Intercepts
  FC ~ mean.FC*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1

  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0

  # set constraints on factor loadings FC for identifiability
  lambdaMF + lambdaMO + lambdaMY == 3
  lambdaMF + lambdaFO + lambdaFY == 3
  lambdaMO + lambdaFO + lambdaYO == 3
  lambdaMY + lambdaFY + lambdaYO == 3
  '

```

### Results model 3b
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3b/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3b_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3b_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3b.1_fit <- fit_all[c(1:8),]
    rownames(option3b.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3b.2_fit <- fit_all[c(9:16),]
    rownames(option3b.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3b.3_fit <- fit_all[c(17:24),]
    rownames(option3b.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3b.4_fit <- fit_all[c(25:32),]
    rownames(option3b.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  option3b.1_fit
  option3b.2_fit
  option3b.3_fit
  option3b.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```
For all options: All models converged, only with small samples negative variances were found.

Options 1, 2 and 4: CFI and chi-square test perform well with both small (n = 50) and larger samples. TLI performs well starting from n = 75. RMSEA only performs well with samples of 200 families or more. In general, for n = 75, good results with least stringent cut-offs for fit indices. For the most stringent cut-offs: good results for n $\geq$ 100 or 125.

Option 3: chi-square test and RMSEA perform worse with larger samples.

\newpage

# Model 3c: Average all FL of FC = 1

This model yields the most straightforward interpretation of all models in this section. 
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3c <- '
# Latent variables
FC =~ lambdaMF*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
I.M =~ 1*MF + 1*MO + 1*MY
I.F =~ 1*MF + 1*FO + 1*FY
I.O =~ 1*MO  + 1*FO + 1*YO
I.Y =~ 1*MY  + 1*FY + 1*YO
D.MF =~ 1*MF
D.MO =~ 1*MO
D.MY =~ 1*MY
D.FO =~ 1*FO
D.FY =~ 1*FY
D.OY =~ 1*YO

# Variances
FC ~~ VAR.FC*FC
I.M ~~ VAR.I.M*I.M
I.F ~~ VAR.I.F*I.F
I.O ~~ VAR.I.O*I.O
I.Y ~~ VAR.I.Y*I.Y
D.MF ~~ VAR.D.MF*D.MF
D.MO ~~ VAR.D.MO*D.MO
D.MY ~~ VAR.D.MY*D.MY
D.FO ~~ VAR.D.FO*D.FO
D.FY ~~ VAR.D.FY*D.FY
D.OY ~~ VAR.D.OY*D.OY

# Intercepts
FC ~ mean.FC*1
I.M ~ mean.I.M*1
I.F ~ mean.I.F*1
I.O ~ mean.I.O*1
I.Y ~ mean.I.Y*1
D.MF ~ mean.D.MF*1
D.MO ~ mean.D.MO*1
D.MY ~ mean.D.MY*1
D.FO ~ mean.D.FO*1
D.FY ~ mean.D.FY*1
D.OY ~ mean.D.OY*1

# Constraints
mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
mean.D.MF + mean.D.MO + mean.D.MY == 0
mean.D.MF + mean.D.FO +  mean.D.FY == 0
mean.D.MY + mean.D.FY + mean.D.OY == 0
mean.D.MO + mean.D.FO + mean.D.OY == 0

# set constraints on factor loadings FC for identifiability
lambdaMF + lambdaMO + lambdaMY + lambdaFO + lambdaFY + lambdaYO == 6
'
```

### Results model 3c
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3c/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3c.1_fit <- fit_all[c(1:8),]
    rownames(option3c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.2_fit <- fit_all[c(9:16),]
    rownames(option3c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.3_fit <- fit_all[c(17:24),]
    rownames(option3c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.4_fit <- fit_all[c(25:32),]
    rownames(option3c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option3c.1_fit,2)
  option3c.2_fit
  option3c.3_fit
  option3c.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

\begin{itemize}
\item Option 1: A lot of models did not converge (n = 50: only 2\% did; n = 150: only 72.6\% did). Also, a lot of negative variances where present in smaller samples. Starting from n = 100: good results.
\item Option 2, 3 and 4: even with small samples we achieve good results. 
\end{itemize}


UPDATE: The analyses were redone because the models that did converged fitted the data very well. I hereby increased the number of iterations from 250 to 20000. The results are shown below.
Results: By increasing the number of iterations, all models converged for samples n = 150. But, the convergence problem persisted with smaller samples. The models that did converge, show an excellent fit, though. Even with small samples.

```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3c met 20000 iteraties/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3c.1_fit <- fit_all[c(1:8),]
    rownames(option3c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.2_fit <- fit_all[c(9:16),]
    rownames(option3c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.3_fit <- fit_all[c(17:24),]
    rownames(option3c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.4_fit <- fit_all[c(25:32),]
    rownames(option3c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

```{r, message = F, warning=F}
# How did the fit measures react?
  round(option3c.1_fit,2)
  option3c.2_fit
  option3c.3_fit
  option3c.4_fit
```


In order to overcome this convergence problem: constrains are set to the variances. As variances can never be negative, the code below forces them to be positive. These constraints are in line with other software like EQS.

```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3c_nonegvar <- '
# Latent variables
FC =~ lambdaMF*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
I.M =~ 1*MF + 1*MO + 1*MY
I.F =~ 1*MF + 1*FO + 1*FY
I.O =~ 1*MO  + 1*FO + 1*YO
I.Y =~ 1*MY  + 1*FY + 1*YO
D.MF =~ 1*MF
D.MO =~ 1*MO
D.MY =~ 1*MY
D.FO =~ 1*FO
D.FY =~ 1*FY
D.OY =~ 1*YO

# Variances
FC ~~ VAR.FC*FC
I.M ~~ VAR.I.M*I.M
I.F ~~ VAR.I.F*I.F
I.O ~~ VAR.I.O*I.O
I.Y ~~ VAR.I.Y*I.Y
D.MF ~~ VAR.D.MF*D.MF
D.MO ~~ VAR.D.MO*D.MO
D.MY ~~ VAR.D.MY*D.MY
D.FO ~~ VAR.D.FO*D.FO
D.FY ~~ VAR.D.FY*D.FY
D.OY ~~ VAR.D.OY*D.OY

# Intercepts
FC ~ mean.FC*1
I.M ~ mean.I.M*1
I.F ~ mean.I.F*1
I.O ~ mean.I.O*1
I.Y ~ mean.I.Y*1
D.MF ~ mean.D.MF*1
D.MO ~ mean.D.MO*1
D.MY ~ mean.D.MY*1
D.FO ~ mean.D.FO*1
D.FY ~ mean.D.FY*1
D.OY ~ mean.D.OY*1

  # no negative variances allowed.
  VAR.FC  > 0
  VAR.I.M > 0
  VAR.I.F > 0
  VAR.I.O > 0
  VAR.I.Y > 0
  VAR.D.MF > 0
  VAR.D.MO > 0
  VAR.D.MY > 0
  VAR.D.FO > 0
  VAR.D.FY > 0
  VAR.D.OY > 0

# Constraints
mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
mean.D.MF + mean.D.MO + mean.D.MY == 0
mean.D.MF + mean.D.FO +  mean.D.FY == 0
mean.D.MY + mean.D.FY + mean.D.OY == 0
mean.D.MO + mean.D.FO + mean.D.OY == 0

# set constraints on factor loadings FC for identifiability
lambdaMF + lambdaMO + lambdaMY + lambdaFO + lambdaFY + lambdaYO == 6
'
```

```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/CODE VOOR PAPER/simulatiestudies/extra simulaties model 3c (no neg var)/alles in 1 script. Kloppen voorgaande resultaten wel")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FC                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FC
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3c.1_fit <- fit_all[c(1:8),]
    rownames(option3c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.2_fit <- fit_all[c(9:16),]
    rownames(option3c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.3_fit <- fit_all[c(17:24),]
    rownames(option3c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.4_fit <- fit_all[c(25:32),]
    rownames(option3c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option3c.1_fit,2)
  option3c.2_fit
  option3c.3_fit
  option3c.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

This model performs very well. By adding these constraints, the convergence problem got completely solved since now all models converged. Also, the fit indices perform very well with all underlying models. General conclusions and guidelines can be made:


```{r, echo = FALSE, message = F, results = 'asis', warning = FALSE}
library(knitr)
Index <- c("CFI", "", "TLI", "", "RMSEA", "", "CHI2(p-value)", "SRMR", "")
Cut_off <- c("0.90", "0.95", "0.90", "0.95", "0.08", "0.04", "0.05", "0.10", "0.08")
Minimal_sample_size <- c(50, 50, 75, 150, 200, "500 < n < 1000", 50, 50, 50)
res <- cbind(Index, Cut_off, Minimal_sample_size)
kable(res)
```


\newpage

# General conclusion: The different models
The model that uses the lambda approach for the family component (with all variances constrained to be positive) is highly recommended. First of all, its interpretation of the different components is the most straightforward out of all variations of Kenny's specification. Also, the fit measures perform very well and their performance does not depend on the true underlying model.

Detailed results:

Model 1 only fitted well when in reality all observed scores are of equal importance for the family component (option 1), but not with the other options. 

Method 2: 
\begin{itemize} 
  \item Models 2a and 2b perform well, especially if n $\geq$ 75
  \item Model 2c performs badly with the simulated datasets of option 2 when 75 $\leq$ n $\leq$ 500 (exception: CFI)
  \item Model 2d shows excellent fit indices for all sample sizes. However, with n $\leq$ 125, models do not always converge.
\end{itemize}


Method 3: 
\begin{itemize} 
  \item Models 3a and 3b: all models converged using the default 250 iterations. Model 3a resulted in a lot of negative variances in small samples, though. Also, data simulated under option 2 resulted in a lot of negative variances (if n $\leq$ 200). For model 3b, this problem only occurred with the smallest samples. For both models, when n = 75, we found good results with the least stringent cut-offs for the fit indices. For the stringent cut-offs: good results were found if n $\geq$ 100 or 125.
  \item Model 3c is the preferred model.  The fit indices perform well with all underlying true models and all models converged.
\end{itemize}
