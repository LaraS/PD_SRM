---
title: "Appendix A: Simulation Studies for Model Selection"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
# Simulate data: The "true model"
Different options for the factor loadings (FL) of the family effect
\begin{itemize}
\item Option 1: all observed scores are of equal importance for the family effect (FE) => constrain every loading to 1, sum will be equal to 6 (identical to simulation study with traditional SRM)
\item[] o1 <- "FE =~ 1*MF + 1*MO + 1*MY + 1*FO + 1*FY + 1*YO"
\item Option 2: some FL's are more important than others, but sum of all is equal to 6 (lambda approach)
\item[] o2 <- "FE =~ 1.4*MF + 0.8*MO + 0.8*MY + 0.8*FO + 0.8*FY + 1.4*YO"
\item Option 3: fix 1 FL to 1 and for the other FL's we will use the lambda approach (based on model 3a; lambda approach) => sum is equal to 6
\item[] o3 <- "FE =~ 1*MF + 0.9*MO + 1.2*MY + 1.1*FO + 1.2*FY + 0.6*YO"
\item Option 4: lambda for each person (based on model 3b) => sum is equal to 6
\item[] o4 <- "FE =~ 0.7*MF + 1.1*MO + 1.2*MY + 1.2*FO + 1.1*FY + 0.7*YO"
\end{itemize}


```{r, eval = F, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51)}
# Factor loadings for FE:
# option 1: all observed scores are of equal importance for the family effect (FE) 
# => constrain every loading to 1, sum will be equal to 6 (identical to simulation
#                                                          study with traditional SRM)
  o1 <- "FE =~ 1*MF + 1*MO + 1*MY + 1*FO + 1*FY + 1*YO"
# option 2: some FL's are more important than others, but sum of all is equal to 
# six (lambda approach)
  o2 <- "FE =~ 1.4*MF + 0.8*MO + 0.8*MY + 0.8*FO + 0.8*FY + 1.4*YO"
# option 3: fix 1 FL to 1 and for the other FL's we will use the lambda approach
# (based on model 3a; lambda approach) => sum is equal to 6
  o3 <- "FE =~ 1*MF + 0.9*MO + 1.2*MY + 1.1*FO + 1.2*FY + 0.6*YO"
# option 4: lambda for each person (based on model 3b) => sum is equal to 6
  o4 <- "FE =~ 0.7*MF + 1.1*MO + 1.2*MY + 1.2*FO + 1.1*FY + 0.7*YO"
FE <- c(o1,o2,o3,o4)

for (i in 1:4){ # Factor loadings for FE
  true_t <- paste0(FE[i], 
     '
     I.M =~ 1*MF + 1*MO + 1*MY
     I.F =~ 1*MF + 1*FO + 1*FY 
     I.O =~ 1*MO  + 1*FO + 1*YO
     I.Y =~ 1*MY  + 1*FY + 1*YO
     D.MF =~ 1*MF
     D.MO =~ 1*MO
     D.MY =~ 1*MY
     D.FO =~ 1*FO
     D.FY =~ 1*FY
     D.OY =~ 1*YO
     
     # Variances
     FE ~~ 2*FE
     I.M ~~ 1*I.M
     I.F ~~ 1*I.F
     I.O ~~ 1*I.O
     I.Y ~~ 1*I.Y
     D.MF ~~ 0.5*D.MF
     D.MO ~~ 0.5*D.MO
     D.MY ~~ 0.5*D.MY
     D.FO ~~ 0.5*D.FO
     D.FY ~~ 0.5*D.FY
     D.OY ~~ 0.5*D.OY
     
     # Intercepts
     FE ~ 4*1
     I.M ~ -0.8*1
     I.F ~ -0.8*1
     I.O ~ 0.8*1
     I.Y ~ 0.8*1
     D.MF ~ 1*1
     D.MO ~ -0.5*1
     D.MY ~ -0.5*1
     D.FO ~ -0.5*1
     D.FY ~ -0.5*1
     D.OY ~ 1*1
     ')
  assign(paste0("PDSRM_th_FE", i), true_t)
  }
truemodel <- list(option1 = PDSRM_th_FE1, option2 = PDSRM_th_FE2, option3 = PDSRM_th_FE3, 
                  option4 = PDSRM_th_FE4)
```

\newpage
# Fit different types of models with the simulated data
# Method 1: PD SRM as an adaptation of Kenny's SRM (model 1)
In this model, the factor loadings are all fixed to 1. This is similar to the traditional SRM.

*Note:* For each model, the model syntax is printed. The data simulating loop is not printed for every model because this remains almost identical (only the name of the model changes).
```{r, eval = F, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51)}
  SRM_pd <- '
  # Latent variables
  FE =~ 1*MF + 1*MO + 1*MY + 1*FO + 1*FY + 1*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Intragen. covariances
  #   I.M ~~ I.F
  #   I.O ~~ I.Y
  
  # Variances
  FE ~~ VAR.FE*FE
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAR.D.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FE ~ mean.FE*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '

# Simulations
#############
  setwd("/user/home/gent/vsc408/vsc40825/modelselectie/model1/resultaten")
  N <- 500 # number of simulations
  nobs <- c(50,75,100,125,150,200,500,1000) # different sample sizes
  a <- 1 
  for( k in 1:4){ # which option for FE
    for (j in 1:length(nobs)){
      cfi <- c()
      tli <- c()
      rmsea <- c()
      chi2 <- c()
      srmr <- c()
      neg <- c()
      for(i in 1:N) {
        tryCatch({
          sim.data <- simulateData(truemodel[[k]], seed = a, sample.nobs=nobs[j])
          fit <- lavaan(SRM_pd, data=sim.data)
          cfi[i] <- fitMeasures(fit, "cfi")
          rmsea[i] <- fitMeasures(fit, "rmsea")
          chi2[i] <- fitMeasures(fit, "pvalue")
          tli[i] <- fitMeasures(fit, "tli")
          srmr[i] <- fitMeasures(fit, "srmr")
          name <- paste('nobs', nobs[j], sep='')
          fitvalues <- list(TLI = tli, CFI = cfi, RMSEA = rmsea, CHI2 = chi2, SRMR = srmr)
          neg[i] <- length(which(parameterEstimates(fit)[c(25:35),"est"] <0))
          a <- a + 1
        }, error=function(e){cat("ERROR i=",i, "j=",j,"k=",k , ":",conditionMessage(e),
                                 "\n")})
      } 
      if (!is.null(cfi)){ 
        # only write table when there is at least 1 model that converged 
        write.table(fitvalues, paste0("dataTO",k,"_m1_fit_nobs",nobs[j], ".txt")) 
        # T = theoretical, O = which option for FE
        write.table(neg, paste0("dataTO",k,"_m1_neg_nobs",nobs[j], ".txt"))
      }
    }
  }
```

### Results model 1
Below, the code for analyzing these results is provided. This is only print this once, for the other models I will directly provide the output.

In this output section, different kinds of tables are shown. The first four tables (option1_fit - option4_fit) contain information about 5 different fit measures: The CFI (with a cut-off of .90 and .95), the TLI (with a cut-off of .90 and .95), the RMSEA (with a cut-off of .08 and .04), the SRMR (with a cut-off of .10 and .08) and the p-value of the chi-square (p>.05: there is no significant difference between the data and the model). All results are given in percentage.

The fifth table provides information about how many models converged (\%). The last table shows how many models contained at least one negative variance (\%). 

*Note:* We expect that the chi-square test yields more significant results with larger samples, as documented in literature.
```{r setup, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51)}
  setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model1/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", 
                         "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) 
  # is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m1_fit_nobs",nobs[j]),
         read.table(paste0("dataTO",k,"_m1_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretical data
  # o = which option for FE
  # m = which model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                          "$CFI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO", k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$CFI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$TLI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$TLI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .04))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$CHI2")))) > .05))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .10))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m1_neg_nobs",nobs[j]),
           read.table(paste0("dataTO",k,"_m1_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m1_neg_nobs",nobs[j], 
                                                         "[,1]")))) != 0))/
      length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations that converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m1_fit_nobs",nobs[j],
                                                "$CFI")))))/5  
  }
  }
  
  # results in table format
  option1.1_fit <- fit_all[c(1:8),]
    rownames(option1.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  option1.2_fit <- fit_all[c(9:16),]
    rownames(option1.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  option1.3_fit <- fit_all[c(17:24),]
    rownames(option1.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  option1.4_fit <- fit_all[c(25:32),]
    rownames(option1.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                 "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                         "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                      "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  option1.1_fit
  option1.2_fit
  option1.3_fit
  option1.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

## Conclusion model 1
If in reality all observed scores are of equal importance for the family effect (*option 1* of the simulated data), this model suits very well with these simulated data (as expected).  

If, however, some observed scores are more important than others (*option 2, 3 and 4*), this model will terribly underperform.

*Note:* The RMSEA will underperform with almost all presented models.

\newpage

# Method 2: Set factor loadings free of FE, but fix at least 1
In models 2a, 2b and 2c, the FL's of the family effect are constrained: 
\begin{itemize}
\item[(2a)] the FL's of the dyads of the same generation are fixed to 1
\item[(2b)] the FL's of the parent-child dyads are fixed to 1
\item[(2c)] the FL's of the same person are constrained (here: mother)
\end{itemize}
Here, the assumption is made that the fixed observed variables are of equal importance for the family effect. They also serve as the baseline to which the other observed scores can be compared. 

Model 2d uses a similar approach to ULI (i.e., unit loading identification) for the family effect. Here, the FL of one observed score is constrained to 1, while the others are set free. The constrained observed score serves as a baseline to which the other observed scores can be compared: Are they more (or less) important for the family effect?

In search of a general version of the PD SRM, a priori, model 2d is the most suitable of all three models. Models 2a, 2b and 2c can be used for specific research questions. 

## Model 2a: Constrain dyads from the same generation (6df)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
  SRM_pd2a <- '
  # Latent variables
  FE =~ 1*MF + MO + MY + FO + FY + 1*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Variances
  FE ~~ VAR.FE*FE
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAD.R.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FE ~ mean.FE*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '  
```

### Results model 2a
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2a/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04",
                         "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on 
  # a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j]),
         read.table(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$CFI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$CFI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$TLI")))) > .90))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$TLI")))) > .95))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$RMSEA")))) < .04))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$CHI2")))) > .05))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .10))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                       "$SRMR")))) < .08))/
    length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2a_neg_nobs",nobs[j]),
           read.table(paste0("dataTO",k,"_m2a_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2a_neg_nobs",nobs[j],
                                                         "[,1]")))) != 0))/
      length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2a_fit_nobs",nobs[j],
                                                "$CFI")))))/5  
  }
  }
  
  # results in table format
  option2a.1_fit <- fit_all[c(1:8),]
    rownames(option2a.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  option2a.2_fit <- fit_all[c(9:16),]
    rownames(option2a.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  option2a.3_fit <- fit_all[c(17:24),]
    rownames(option2a.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  option2a.4_fit <- fit_all[c(25:32),]
    rownames(option2a.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200",
                                  "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                         "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500",
                      "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2a.1_fit,2)
  option2a.2_fit
  option2a.3_fit
  option2a.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

\begin{itemize}
\item Option 1: Only 21\% of all models converged with n = 50. With the other three options, all models converged.
\item[] Starting from n = 75: good performance (exception: RMSEA performs only well with larger samples)
\item Option 2 and 3: Also perform well with n = 50 (*Note:* with option 3 the chi-square test becomes more significant as sample size increases) .
\item Option 4: Performs well (expectation chi-square if n $\leq$ 100)
\item With n = 50: data simulated under option 1 and 2 result in fitted models with the most negative variances.
\end{itemize}
RMSEA only performs adequately starting from n = 200
\newpage

## Model 2b: Constrain the parent-child dyads (8df)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
  SRM_pd2b <- '
  # Latent variables
  FE =~ MF + 1*MO + 1*MY + 1*FO + 1*FY + YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Variances
  FE ~~ VAR.FE*FE
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAD.R.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FE ~ mean.FE*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '  
```

### Results model 2b
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2b/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2b_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2b_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2b_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2b_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option2b.1_fit <- fit_all[c(1:8),]
    rownames(option2b.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2b.2_fit <- fit_all[c(9:16),]
    rownames(option2b.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2b.3_fit <- fit_all[c(17:24),]
    rownames(option2b.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2b.4_fit <- fit_all[c(25:32),]
    rownames(option2b.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2b.1_fit,2)
  option2b.2_fit
  option2b.3_fit
  option2b.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

Similar results as with the previous model
\begin{itemize}
\item Option 1: Only 15\% of all models converged with n = 50. With the other three options, all models converged.
\item[] if n $\geq$ 75: fit indices all perform very well 
\item Option 2: also good results with n=50
\item Option 3: CFI, TLI and SRMR perform good. 
\end{itemize}
Exception: RMSEA only performs well in larger samples.
\newpage

## Model 2c: Constrain everything of 1 person (here: mother)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd2c <- '
# Latent variables
FE =~ 1*MF + 1*MO + 1*MY + FO + FY + YO
I.M =~ 1*MF + 1*MO + 1*MY
I.F =~ 1*MF + 1*FO + 1*FY 
I.O =~ 1*MO  + 1*FO + 1*YO
I.Y =~ 1*MY  + 1*FY + 1*YO
D.MF =~ 1*MF
D.MO =~ 1*MO
D.MY =~ 1*MY
D.FO =~ 1*FO
D.FY =~ 1*FY
D.OY =~ 1*YO

# Variances
FE ~~ VAR.FE*FE
I.M ~~ VAR.I.M*I.M
I.F ~~ VAR.I.F*I.F
I.O ~~ VAR.I.O*I.O
I.Y ~~ VAR.I.Y*I.Y
D.MF ~~ VAR.D.MF*D.MF
D.MO ~~ VAR.D.MO*D.MO
D.MY ~~ VAD.R.MY*D.MY
D.FO ~~ VAR.D.FO*D.FO
D.FY ~~ VAR.D.FY*D.FY
D.OY ~~ VAR.D.OY*D.OY

# Intercepts
FE ~ mean.FE*1
I.M ~ mean.I.M*1
I.F ~ mean.I.F*1
I.O ~ mean.I.O*1
I.Y ~ mean.I.Y*1
D.MF ~ mean.D.MF*1
D.MO ~ mean.D.MO*1
D.MY ~ mean.D.MY*1
D.FO ~ mean.D.FO*1
D.FY ~ mean.D.FY*1
D.OY ~ mean.D.OY*1

# Constraints
mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
mean.D.MF + mean.D.MO + mean.D.MY == 0
mean.D.MF + mean.D.FO +  mean.D.FY == 0
mean.D.MY + mean.D.FY + mean.D.OY == 0
mean.D.MO + mean.D.FO + mean.D.OY == 0
'    
```

### Results model 2c
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2c/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option2c.1_fit <- fit_all[c(1:8),]
    rownames(option2c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2c.2_fit <- fit_all[c(9:16),]
    rownames(option2c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2c.3_fit <- fit_all[c(17:24),]
    rownames(option2c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2c.4_fit <- fit_all[c(25:32),]
    rownames(option2c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2c.1_fit,2)
  option2c.2_fit
  option2c.3_fit
  option2c.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

\begin{itemize}
\item Option 1: Only 17\% and 38\% of all models converged with sample sizes of 50 and 75, respectively. For the other sample sizes, the results are all good.
\item Option 2: Except for the smallest sample, model 2c underperforms. This is the case with almost all fit indices (exception: CFI90)
\item Option 3: In general, good fit with n $\geq$ 125 (exceptions: RMSEA and Chi-square)
\item Option 4: In general, good fit with n $\geq$ 200 (exceptions: RMSEA and Chi-square)
\item Option 2-4: Chi-square test (and RMSEA) becomes worse with increasing sample sizes. This is what we would expect for the chi-square test. Also, TLI performs badly with option 2.
\item Negative variances seem to be present with all options in smaller samples
\end{itemize}
Conclusion:  of all models, this model seems to be the least suitable.


\newpage
## Model 2d:  Set factor loadings free of FE, but fix 1 (ULI; 5df)
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
 SRM_pd2d <- '
  # Latent variables
  FE =~ 1*MF + MO + MY + FO + FY + YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY 
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO
  
  # Variances
  FE ~~ VAR.FE*FE
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAD.R.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY
  
  # Intercepts
  FE ~ mean.FE*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1
  
  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  '  
```

### Results model 2d
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model2d/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m2d_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m2d_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m2d_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m2d_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option2d.1_fit <- fit_all[c(1:8),]
    rownames(option2d.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2d.2_fit <- fit_all[c(9:16),]
    rownames(option2d.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2d.3_fit <- fit_all[c(17:24),]
    rownames(option2d.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option2d.4_fit <- fit_all[c(25:32),]
    rownames(option2d.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option2d.1_fit,2)
  option2d.2_fit
  option2d.3_fit
  option2d.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```
Results:
\begin{itemize}
\item If all FL's of the family effect in reality are of equal importance (i.e. $Option 1$), this model underperforms with samples smaller than 200. Only 1.4\% of all models converged with n = 50 and 72.6\% of all models with n = 150 did. Also, a lot of negative variances seem to be present in small samples. For the models that did converged, results were good for samples if n $\geq$ 75 or 100. 
\item The other three kinds of simulated data ($Option 2, 3$ and $4$) perform very well: all models converged and the fit indices as well as the chi-square difference tests showed an excellent model fit. $Note:$ Also the RMSEA performs well.
\end{itemize}



\newpage

# Method 3: lambda approach
In this section, I use the lambda approach for the factor loadings of the family effect. This is an alternative identification strategy where the mean of the factor loadings equals 1. Model 3c is the most general model with the most straightforward interpretation of the components.

# Model 3a: Constrain one FL as a Reference (Sum other FL's = 5).
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3a <- '
  # Latent variables
  FE =~ 1*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO

  # Variances
  FE ~~ VAR.FE*FE
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAR.D.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY

  # Intercepts
  FE ~ mean.FE*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1

  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0
  # set constraints on factor loadings FE for identifiability
  lambdaMO+ lambdaMY+ lambdaFO + lambdaFY + lambdaYO==5
  '
```

### Results model 3a
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3a/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3a_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3a_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3a_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3a_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3a.1_fit <- fit_all[c(1:8),]
    rownames(option3a.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3a.2_fit <- fit_all[c(9:16),]
    rownames(option3a.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3a.3_fit <- fit_all[c(17:24),]
    rownames(option3a.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3a.4_fit <- fit_all[c(25:32),]
    rownames(option3a.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  option3a.1_fit
  option3a.2_fit
  option3a.3_fit
  option3a.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

All models converged. With small samples, a lot of negative variances where found.

Options 1 and 3: CFI and chi-square test perform well with both small (n = 50) and larger samples. TLI performs well starting from n = 75. RMSEA only performs adequately with samples of 200 families or more.

Option 2 and 4: chi-square test and RMSEA perform worse with larger samples. The former is what we could expect.

Option 3: Good results if n $\geq$ 75 for least stringent cut offs.

Drawback: not so easy to interpret the different components.

\newpage

# Model 3b: lambda for every person
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3b <- '
  # Latent variables
  FE =~ lambdaMF*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
  I.M =~ 1*MF + 1*MO + 1*MY
  I.F =~ 1*MF + 1*FO + 1*FY
  I.O =~ 1*MO  + 1*FO + 1*YO
  I.Y =~ 1*MY  + 1*FY + 1*YO
  D.MF =~ 1*MF
  D.MO =~ 1*MO
  D.MY =~ 1*MY
  D.FO =~ 1*FO
  D.FY =~ 1*FY
  D.OY =~ 1*YO

  # Variances
  FE ~~ VAR.FE*FE
  I.M ~~ VAR.I.M*I.M
  I.F ~~ VAR.I.F*I.F
  I.O ~~ VAR.I.O*I.O
  I.Y ~~ VAR.I.Y*I.Y
  D.MF ~~ VAR.D.MF*D.MF
  D.MO ~~ VAR.D.MO*D.MO
  D.MY ~~ VAR.D.MY*D.MY
  D.FO ~~ VAR.D.FO*D.FO
  D.FY ~~ VAR.D.FY*D.FY
  D.OY ~~ VAR.D.OY*D.OY

  # Intercepts
  FE ~ mean.FE*1
  I.M ~ mean.I.M*1
  I.F ~ mean.I.F*1
  I.O ~ mean.I.O*1
  I.Y ~ mean.I.Y*1
  D.MF ~ mean.D.MF*1
  D.MO ~ mean.D.MO*1
  D.MY ~ mean.D.MY*1
  D.FO ~ mean.D.FO*1
  D.FY ~ mean.D.FY*1
  D.OY ~ mean.D.OY*1

  # Constraints
  mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
  mean.D.MF + mean.D.MO + mean.D.MY == 0
  mean.D.MF + mean.D.FO +  mean.D.FY == 0
  mean.D.MY + mean.D.FY + mean.D.OY == 0
  mean.D.MO + mean.D.FO + mean.D.OY == 0

  # set constraints on factor loadings FE for identifiability
  lambdaMF + lambdaMO + lambdaMY == 3
  lambdaMF + lambdaFO + lambdaFY == 3
  lambdaMO + lambdaFO + lambdaYO == 3
  lambdaMY + lambdaFY + lambdaYO == 3
  '

```

### Results model 3b
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3b/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3b_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3b_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3b_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3b_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3b.1_fit <- fit_all[c(1:8),]
    rownames(option3b.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3b.2_fit <- fit_all[c(9:16),]
    rownames(option3b.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3b.3_fit <- fit_all[c(17:24),]
    rownames(option3b.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3b.4_fit <- fit_all[c(25:32),]
    rownames(option3b.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  option3b.1_fit
  option3b.2_fit
  option3b.3_fit
  option3b.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```
For all options: All models converged, only with small samples negative variances were found.

Options 1, 2 and 4: CFI and chi-square test perform well with both small (n = 50) and larger samples. TLI performs well starting from n = 75. RMSEA only performs well with samples of 200 families or more. In general, for n = 75: good results with least stringent cut-offs for fit indices. For the stringent cut-offs: good results for n $\geq$ 100 or 125.

Option 3: chi-square test and RMSEA perform worse with larger samples.

\newpage

# Model 3c: Average all FL of FC = 1

This model yields the most straightforward interpretation of all models of this section. 
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3c <- '
# Latent variables
FE =~ lambdaMF*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
I.M =~ 1*MF + 1*MO + 1*MY
I.F =~ 1*MF + 1*FO + 1*FY
I.O =~ 1*MO  + 1*FO + 1*YO
I.Y =~ 1*MY  + 1*FY + 1*YO
D.MF =~ 1*MF
D.MO =~ 1*MO
D.MY =~ 1*MY
D.FO =~ 1*FO
D.FY =~ 1*FY
D.OY =~ 1*YO

# Variances
FE ~~ VAR.FE*FE
I.M ~~ VAR.I.M*I.M
I.F ~~ VAR.I.F*I.F
I.O ~~ VAR.I.O*I.O
I.Y ~~ VAR.I.Y*I.Y
D.MF ~~ VAR.D.MF*D.MF
D.MO ~~ VAR.D.MO*D.MO
D.MY ~~ VAR.D.MY*D.MY
D.FO ~~ VAR.D.FO*D.FO
D.FY ~~ VAR.D.FY*D.FY
D.OY ~~ VAR.D.OY*D.OY

# Intercepts
FE ~ mean.FE*1
I.M ~ mean.I.M*1
I.F ~ mean.I.F*1
I.O ~ mean.I.O*1
I.Y ~ mean.I.Y*1
D.MF ~ mean.D.MF*1
D.MO ~ mean.D.MO*1
D.MY ~ mean.D.MY*1
D.FO ~ mean.D.FO*1
D.FY ~ mean.D.FY*1
D.OY ~ mean.D.OY*1

# Constraints
mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
mean.D.MF + mean.D.MO + mean.D.MY == 0
mean.D.MF + mean.D.FO +  mean.D.FY == 0
mean.D.MY + mean.D.FY + mean.D.OY == 0
mean.D.MO + mean.D.FO + mean.D.OY == 0

# set constraints on factor loadings FE for identifiability
lambdaMF + lambdaMO + lambdaMY + lambdaFO + lambdaFY + lambdaYO == 6
'
```

### Results model 3c
```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3c/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3c.1_fit <- fit_all[c(1:8),]
    rownames(option3c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.2_fit <- fit_all[c(9:16),]
    rownames(option3c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.3_fit <- fit_all[c(17:24),]
    rownames(option3c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.4_fit <- fit_all[c(25:32),]
    rownames(option3c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option3c.1_fit,2)
  option3c.2_fit
  option3c.3_fit
  option3c.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

\begin{itemize}
\item Option 1: A lot of models did not converge (n = 50: only 2\% did; n = 150: only 72.6\% did). Also, a lot of negative variances where present in smaller samples. Starting from n = 100: good results.
\item Option 2, 3 and 4: even with small samples we achieve good results. 
\end{itemize}


UPDATE: The analyses were redone because the models that did converged fitted very well with the data. I hereby increased the number of iterations from 250 to 20000. The results are shown below.
Result: By increasing the number of iterations, all models converged for samples n = 150. But, the convergence problem persisted with smaller samples. The models that did converge, show an excellent fit, though. Even with small samples.

```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/Gebruikt vanaf 10-2-2017/Simulaties model selection/3de simulaties/model3c met 20000 iteraties/resultaten")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3c.1_fit <- fit_all[c(1:8),]
    rownames(option3c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.2_fit <- fit_all[c(9:16),]
    rownames(option3c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.3_fit <- fit_all[c(17:24),]
    rownames(option3c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.4_fit <- fit_all[c(25:32),]
    rownames(option3c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

```{r, message = F, warning=F}
# How many models had at least 1 negative variance (%)?
  round(neg_all,2)
```

```{r, message = F, warning=F}
# How did the fit measures react?
  round(option3c.1_fit,2)
  option3c.2_fit
  option3c.3_fit
  option3c.4_fit
```


In order to overcome this convergence problem: constrains are set to the variances. As variances can never be negative, the code below forces them to be positive. These constraints are in line with other software like, for example, EQS.

```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), eval = F}
SRM_pd3c_nonegvar <- '
# Latent variables
FE =~ lambdaMF*MF + lambdaMO*MO + lambdaMY*MY + lambdaFO*FO + lambdaFY*FY + lambdaYO*YO
I.M =~ 1*MF + 1*MO + 1*MY
I.F =~ 1*MF + 1*FO + 1*FY
I.O =~ 1*MO  + 1*FO + 1*YO
I.Y =~ 1*MY  + 1*FY + 1*YO
D.MF =~ 1*MF
D.MO =~ 1*MO
D.MY =~ 1*MY
D.FO =~ 1*FO
D.FY =~ 1*FY
D.OY =~ 1*YO

# Variances
FE ~~ VAR.FE*FE
I.M ~~ VAR.I.M*I.M
I.F ~~ VAR.I.F*I.F
I.O ~~ VAR.I.O*I.O
I.Y ~~ VAR.I.Y*I.Y
D.MF ~~ VAR.D.MF*D.MF
D.MO ~~ VAR.D.MO*D.MO
D.MY ~~ VAR.D.MY*D.MY
D.FO ~~ VAR.D.FO*D.FO
D.FY ~~ VAR.D.FY*D.FY
D.OY ~~ VAR.D.OY*D.OY

# Intercepts
FE ~ mean.FE*1
I.M ~ mean.I.M*1
I.F ~ mean.I.F*1
I.O ~ mean.I.O*1
I.Y ~ mean.I.Y*1
D.MF ~ mean.D.MF*1
D.MO ~ mean.D.MO*1
D.MY ~ mean.D.MY*1
D.FO ~ mean.D.FO*1
D.FY ~ mean.D.FY*1
D.OY ~ mean.D.OY*1

  # no negative variances allowed.
  VAR.FE  > 0
  VAR.I.M > 0
  VAR.I.F > 0
  VAR.I.O > 0
  VAR.I.Y > 0
  VAR.D.MF > 0
  VAR.D.MO > 0
  VAR.D.MY > 0
  VAR.D.FO > 0
  VAR.D.FY > 0
  VAR.D.OY > 0

# Constraints
mean.I.M + mean.I.F +  mean.I.O + mean.I.Y == 0
mean.D.MF + mean.D.MO + mean.D.MY == 0
mean.D.MF + mean.D.FO +  mean.D.FY == 0
mean.D.MY + mean.D.FY + mean.D.OY == 0
mean.D.MO + mean.D.FO + mean.D.OY == 0

# set constraints on factor loadings FE for identifiability
lambdaMF + lambdaMO + lambdaMY + lambdaFO + lambdaFY + lambdaYO == 6
'
```

```{r, message = F, warning=F, tidy=TRUE, tidy.opts=list(width.cutoff=51), include= F}
 setwd("H:/home/Doctoraat/Studie 3 - PD SRM/Code/CODE VOOR PAPER/simulatiestudies/extra simulaties model 3c (no neg var)")
  nobs <- c(50,75,100,125,150,200,500,1000)
  fit_all <- as.data.frame(matrix(NA, ncol= 9, nrow = 32))
  colnames(fit_all) <- c("CFI90", "CFI95", "TLI90", "TLI95", "RMSEA08", "RMSEA04", "CHI2", "SRMR10", "SRMR08")
  neg_all <- as.data.frame(matrix(NA, ncol= 4, nrow = 8))
  colnames(neg_all) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  conv <- as.data.frame(matrix(NA, ncol = 4, nrow = 8))
  colnames(conv) <- c("optie 1", "optie 2", "optie 3", "optie 4")
  # which option for FE                         
  for( k in 1:4){ 
  # 8 different sample sizes
  for (j in 1:length(nobs)){
  # make index i, so every unique combination (of option and sample size) is written on a new (ith) row
  l <- k-1
  i <- j + (l*8) 
  # fit measures:
  assign(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j], ".txt"))) 
  # T = theoretische data
  # o = welke optie voor FE
  # m = welk model
  #how many models have a good fit (%)?
  fit_all[i,1] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,2] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100 
  fit_all[i,3] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .90))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,4] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$TLI")))) > .95))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,5] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,6] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$RMSEA")))) < .04))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,7] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CHI2")))) > .05))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,8] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .10))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  fit_all[i,9] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$SRMR")))) < .08))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # negative variances:
    assign(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j]), read.table(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], ".txt")))
    # percentage of simulations that had at least 1 negative variance
    neg_all[j,k] <- length(which(eval(parse(text=(paste0("dataTO",k,"_m3c_neg_nobs",nobs[j], "[,1]")))) != 0))/length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))*100
  # percentage of all simulations where model converged
    conv[j,k] <- length(eval(parse(text=(paste0("dataTO",k,"_m3c_fit_nobs",nobs[j],"$CFI")))))/5  
  }
  }
  
  # results in table format
  option3c.1_fit <- fit_all[c(1:8),]
    rownames(option3c.1_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.2_fit <- fit_all[c(9:16),]
    rownames(option3c.2_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.3_fit <- fit_all[c(17:24),]
    rownames(option3c.3_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  option3c.4_fit <- fit_all[c(25:32),]
    rownames(option3c.4_fit) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(neg_all) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
  rownames(conv) <- c("n=50", "n=75", "n=100", "n=125", "n=150", "n=200", "n=500", "n=1000")
```


```{r, message = F, warning=F}
# How did the fit measures react?
  round(option3c.1_fit,2)
  option3c.2_fit
  option3c.3_fit
  option3c.4_fit
```

```{r, message = F, warning=F}
# How many models converged (%)?
  conv
```

The results of this model are excellent. All fit indices show an excellent performance, regardless of the cut-off and the underlying true model. All models converged.





\newpage

# General conclusion: The different models
The model that uses the lambda approach for the family component (with all variances constrained to be positive) is highly recommended. First of all, its interpretation of the different components is the most straightforward out of all variations of Kenny's model. Also, all fit measures perform very well even with the most stringent cut-offs. Their performance does not depend on the true underlying model.

Detailed results:

Model 1 only fitted well when in reality all observed scores are of equal importance for the family effect (option 1), but not with the other options. 

Method 2: 
\begin{itemize} 
  \item Models 2a and 2b perform well, especially if n $\geq$ 75
  \item Model 2c performs badly with the simulated datasets of option 2 when 75 $\leq$ n $\leq$ 500 (exception: CFI)
  \item Model 2d shows excellent fit indices for all sample sizes. However, with n $\leq$ 125, models do not always converge.
\end{itemize}


Method 3: 
\begin{itemize} 
  \item Models 3a and 3b: all models converged using the default 250 iterations. Model 3a resulted in a lot of negative variances in small samples, though. Also, data simulated under option 2 resulted in a lot of negative variances (if n $\leq$ 200). For model 3b, this problem only occurred with the smallest samples. For both models, when n = 75, we found good results with the least stringent cut-offs for the fit indices. For the stringent cut-offs: good results were found if n $\geq$ 100 or 125.
  \item Model 3c shows excellent fit indices for all sample sizes. 
\end{itemize}

# General conclusion: Fit measures for these kinds of models
For model 3c (lambda approach), with the variances constrained to be positive, all fit measures perform very well. 

For the other models the following guidelines can be given:

The RMSEA only seems to be useful for sample sizes starting from 200. After a literature review, I found that this has been documented before (Kenny, Kaniskan, \& McCoach, 2015; Taasoobshirazi \& Wang, 2016). These authors found that models with a combination of a small amount of degrees of freedom and smaller sample sizes had RMSEA values that often falsely indicated a poor model fit. Taasoobshirazi and Wang (2016) advised to avoid reporting the RMSEA when sample sizes are smaller than 200. I agree with this advice for our PD SRM.

Li-tze and Bentler (1999) state that the SRMR is the most sensitive index to models with misspecified factor covariance(s) or latent structure, and the TLI, CFI and RMSEA are the most sensitive indexes to models with misspecified factor loadings. In line with this research, we can recommend a two-index presentation strategy that includes using the CFI and TLI and supplementing it with the SRMR.

Here, the recommended cut-off for the CFI and TLI seems to be .90 in small samples. Of these two incremental fit indexes, the results of the simulation study suggest that the CFI is the most recommended index when using a small sample. This conclusion is in line with our other simulations study using the traditional SRM. 

For the SRMR, .10 is a more suitable cut-off for samples smaller than 125. For larger samples, the cut-off of .08 seems to be adequate.

In some cases, the chi-square test become more frequently significant with larger sample sizes. This is what we could expect from the chi-square test. Additionally, Prof. Kenny reports on his website that the chi-square test tends to be ok if 75 < n < 200. Also, he said this test would be too liberal for non-normal distributions. With purely dyadic data, we will often have very skewed distributions. This is something to keep in mind. 

